{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining LPC (Linear Prediction Coefficients) for speech command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "import wave\n",
    "import math\n",
    "import cmath\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from scipy.io.wavfile import read\n",
    "from audiolazy import lazy_lpc as lpc\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rossignol_set = []\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"enavant.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"enavant2.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"enavant3.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"adroite.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"adroite2.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"adroite3.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"agauche.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"agauche2.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"agauche3.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"stop.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"stop2.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "rossignol_set.append({\n",
    "    \"filename\": \"stop3.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "remi_set = []\n",
    "remi_set.append({\n",
    "    \"filename\": \"enavant_1_remi.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"enavant_2_remi.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"enavant_3_remi.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"adroite_1_remi.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"adroite_2_remi.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"adroite_3_remi.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"agauche_1_remi.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"agauche_2_remi.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"agauche_3_remi.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"stop_1_remi.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"stop_2_remi.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "remi_set.append({\n",
    "    \"filename\": \"stop_3_remi.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "paul_set = []\n",
    "paul_set.append({\n",
    "    \"filename\": \"enavant_1_paul.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"enavant_2_paul.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"enavant_3_paul.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"adroite_1_paul.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"adroite_2_paul.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"adroite_3_paul.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"agauche_1_paul.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"agauche_2_paul.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"agauche_3_paul.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"stop_1_paul.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"stop_2_paul.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})\n",
    "paul_set.append({\n",
    "    \"filename\": \"stop_3_paul.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "paul_set_reduce = []\n",
    "paul_set_reduce.append({\n",
    "    \"filename\": \"enavant_1_paul.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "paul_set_reduce.append({\n",
    "    \"filename\": \"adroite_1_paul.wav\",\n",
    "    \"class\": \"right\",\n",
    "})\n",
    "paul_set_reduce.append({\n",
    "    \"filename\": \"agauche_1_paul.wav\",\n",
    "    \"class\": \"left\",\n",
    "})\n",
    "paul_set_reduce.append({\n",
    "    \"filename\": \"stop_1_paul.wav\",\n",
    "    \"class\": \"stop\",\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "simon_set = []\n",
    "simon_set.append({\n",
    "    \"filename\": \"enavant_1_simon.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "simon_set.append({\n",
    "    \"filename\": \"enavant_2_simon.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})\n",
    "simon_set.append({\n",
    "    \"filename\": \"enavant_3_simon.wav\",\n",
    "    \"class\": \"forward\",\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building our set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# signal_wave = wave.open(\"data/enavant.wav\")\n",
    "# (nchannels, sampwidth, framerate, nframes, comptype, compname) = signal_wave.getparams()\n",
    "\n",
    "# [fs, a] = read(\"data/enavant.wav\")\n",
    "# sig_in = np.array(a)\n",
    "\n",
    "# nbytes_fen = fs * 0.03 # 480\n",
    "# nbytes_pas = fs * 0.01 # 160\n",
    "\n",
    "# signals = []\n",
    "\n",
    "# for i in np.arange(0, len(sig_in), 160, dtype=int):\n",
    "#     signals.append(sig_in[i:i+480])\n",
    "    \n",
    "# print(len(signals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phi(signal, k_ind):\n",
    "    # phi est un estimateur de la fonction d'autocorrélation du signal\n",
    "    N = len(signal)\n",
    "    somme = 0\n",
    "    for i in range(0, N - k_ind):\n",
    "        somme += signal[i] * signal[i + k_ind]\n",
    "    return (somme / N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dsp_calculation_audiolazy(signal, K, a, nu): \n",
    "    sum_sigma = 0\n",
    "    for i in range(0, K):\n",
    "        sum_sigma += a[i] * phi(signal, i)\n",
    "    sigma_e = phi(signal, 0) - sum_sigma\n",
    "    sum_den_dsp = 0\n",
    "    for j in range(0, K):\n",
    "        sum_den_dsp += a[j] * cmath.exp(2 * cmath.pi * nu * j * 1j)\n",
    "    den_dsp = (abs(1 - sum_den_dsp))**2\n",
    "    dsp = 0\n",
    "    if (den_dsp != 0 and sigma_e != 0):\n",
    "        dsp = sigma_e / den_dsp\n",
    "    return dsp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(filename):\n",
    "    signal_wave = wave.open(filename)\n",
    "    (nchannels, sampwidth, framerate, nframes, comptype, compname) = signal_wave.getparams()\n",
    "\n",
    "    [fs, a] = read(filename)\n",
    "    sig_in = np.array(a)\n",
    "\n",
    "    nbytes_fen = fs * 0.03 # 480\n",
    "    nbytes_pas = fs * 0.01 # 160\n",
    "\n",
    "    signals = []\n",
    "\n",
    "    for i in np.arange(0, len(sig_in), 160, dtype=int):\n",
    "        signals.append(sig_in[i:i+480])\n",
    "        \n",
    "    K = 10\n",
    "    a_arr = []\n",
    "    dsp_arr = []\n",
    "    t = np.arange(0, 0.01 * len(signals), 0.01)\n",
    "    f = range(0, 2000, 100)\n",
    "\n",
    "    # Il faut boucler sur tous les échantillons de notre son (rappel, on a pris des fenêtres de 30ms)\n",
    "    for i in range(0, len(signals)):\n",
    "        filt = lpc.lpc.kautocor(signals[i], K)\n",
    "        # a = filt.numerator\n",
    "        a = lpc.lsf(filt)\n",
    "        a_arr.append(a)\n",
    "        dsp_int_arr = []\n",
    "        for j in f:\n",
    "            nu = j / fs\n",
    "            dsp = dsp_calculation_audiolazy(signals[i], K, a, nu)\n",
    "            dsp_int_arr.append(dsp)\n",
    "        dsp_arr.append(dsp_int_arr)\n",
    "        \n",
    "        \n",
    "    dsp_arr_np = np.array(dsp_arr)\n",
    "    # return a_arr\n",
    "    return dsp_arr_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def altDTWDistance(s1, s2,w):\n",
    "    DTW={}\n",
    "\n",
    "    w = max(w, abs(len(s1)-len(s2)))\n",
    "\n",
    "    for i in range(-1,len(s1)):\n",
    "        for j in range(-1,len(s2)):\n",
    "            DTW[(i, j)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(max(0, i-w), min(len(s2), i+w)):\n",
    "            dist= np.sqrt(sum(np.abs((s1[i]-s2[j])**2)))\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return DTW[len(s1)-1, len(s2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DTWDistance(s1, s2):\n",
    "    DTW={}\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        DTW[(i, -1)] = float('inf')\n",
    "    for i in range(len(s2)):\n",
    "        DTW[(-1, i)] = float('inf')\n",
    "    DTW[(-1, -1)] = 0\n",
    "\n",
    "    for i in range(len(s1)):\n",
    "        for j in range(len(s2)):\n",
    "            dist= np.sqrt(sum(np.abs((s1[i]-s2[j]))**2))\n",
    "            DTW[(i, j)] = dist + min(DTW[(i-1, j)],DTW[(i, j-1)], DTW[(i-1, j-1)])\n",
    "\n",
    "    return DTW[len(s1)-1, len(s2)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def diff_mfcc(s1, s2):\n",
    "#     diff = []\n",
    "#     for i in range(0, min(len(s1), len(s2))):\n",
    "#         current_diff = s1[i] - s2[i]\n",
    "#         diff.append(current_diff)\n",
    "#     plt.pcolormesh(np.real(diff))\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_nn(distance, k):\n",
    "    classes = [0, 0, 0, 0]\n",
    "    for i in range(k):\n",
    "        minDist = {'dist': 100000000000000000}\n",
    "        for j in range(len(distance)):\n",
    "            dist = distance[j]['dtw']\n",
    "            if dist == 0:\n",
    "                continue\n",
    "            elif dist < minDist.get('dist'):\n",
    "                minDist = {'dist': dist, 'class': distance[j]['class'], 'idx': j}\n",
    "        distance.pop(minDist.get('idx'))\n",
    "        if minDist.get('class') == 'forward':\n",
    "            classes[0] = classes[0] + 1\n",
    "        elif minDist.get('class') == 'right':\n",
    "            classes[1] = classes[1] + 1\n",
    "        elif minDist.get('class') == 'left':\n",
    "            classes[2] = classes[2] + 1\n",
    "        elif minDist.get('class') == 'stop':\n",
    "            classes[3] = classes[3] + 1\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_set(folder, files):\n",
    "    for fileIdx in range(len(files)):\n",
    "        filename = files[fileIdx].get('filename')\n",
    "        mfcc = process_file(folder + filename)\n",
    "        files[fileIdx]['mfcc'] = mfcc\n",
    "    return files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_set_to_reference(test_set, reference_set, verbose=False):\n",
    "    good_predictions = [0,0,0,0]\n",
    "    for fileIdx1 in range(len(test_set)):\n",
    "        file1 = test_set[fileIdx1]\n",
    "        dtw_distance = []\n",
    "        for fileIdx2 in range(len(reference_set)):\n",
    "            file2 = reference_set[fileIdx2]\n",
    "            dtw_distance.append({'class': file2.get('class'), 'dtw': altDTWDistance(file1.get('mfcc'), file2.get('mfcc'), 15)})\n",
    "        if verbose:\n",
    "            print(file1.get('filename') + ':')\n",
    "        classes = get_k_nn(dtw_distance, 1)\n",
    "        if(max(classes) == classes[0]):\n",
    "            if(file1.get('class') == 'forward'):\n",
    "                if verbose:\n",
    "                    print('TRUE')\n",
    "                good_predictions[0] += 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('FALSE')\n",
    "            test_set[fileIdx1]['prediction'] = 'forward'\n",
    "        elif(max(classes) == classes[1]):\n",
    "            if(file1.get('class') == 'right'):\n",
    "                if verbose:\n",
    "                    print('TRUE')\n",
    "                good_predictions[1] += 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('FALSE')\n",
    "            test_set[fileIdx1]['prediction'] = 'right'\n",
    "        elif(max(classes) == classes[2]):\n",
    "            if(file1.get('class') == 'left'):\n",
    "                if verbose:\n",
    "                    print('TRUE')\n",
    "                good_predictions[2] += 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('FALSE')\n",
    "            test_set[fileIdx1]['prediction'] = 'left'\n",
    "        elif(max(classes) == classes[3]):\n",
    "            if(file1.get('class') == 'stop'):\n",
    "                if verbose:\n",
    "                    print('TRUE')\n",
    "                good_predictions[3] += 1\n",
    "            else:\n",
    "                if verbose:\n",
    "                    print('FALSE')\n",
    "            test_set[fileIdx1]['prediction'] = 'stop'   \n",
    "        if verbose:\n",
    "            print(classes)\n",
    "    print('\\nGood Predictions:')\n",
    "    print(good_predictions)\n",
    "    print('\\nAccuracy:')\n",
    "    print(str(math.floor(sum(good_predictions)/(len(test_set))*100)) + '%')\n",
    "    return test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/audiolazy/lazy_analysis.py:307: RuntimeWarning: overflow encountered in short_scalars\n",
      "  return [sum(blk[n] * blk[n + tau] for n in xrange(len(blk) - tau))\n",
      "/usr/lib/python3/dist-packages/ipykernel_launcher.py:6: RuntimeWarning: overflow encountered in short_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Good Predictions:\n",
      "[1, 0, 0, 0]\n",
      "\n",
      "Accuracy:\n",
      "33%\n"
     ]
    }
   ],
   "source": [
    "reference_set = compute_set(folder=folder, files=paul_set_reduce)\n",
    "test_set = compute_set(folder=folder, files=simon_set)\n",
    "test_set = test_set_to_reference(test_set=test_set, reference_set=reference_set, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "nteract": {
   "version": "0.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
